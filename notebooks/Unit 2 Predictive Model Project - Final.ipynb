{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/users/nchib/DS5/DS-Unit-2-Project/dash-app-template/notebooks/data/df_final1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102840, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @Papapishu: Man it would fucking rule if we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>It is time to draw close to Him &amp;#128591;&amp;#127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>if you notice me start to act different or dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Forget unfollowers, I believe in growing. 7 ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @Vitiligoprince: Hate Being sexually Frustr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  RT @Papapishu: Man it would fucking rule if we...\n",
       "1      2  It is time to draw close to Him &#128591;&#127...\n",
       "2      2  if you notice me start to act different or dis...\n",
       "3      2  Forget unfollowers, I believe in growing. 7 ne...\n",
       "4      1  RT @Vitiligoprince: Hate Being sexually Frustr..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - predict majority class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.558139\n",
       "1    0.387904\n",
       "0    0.053958\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "\n",
    "stopwords=pd.read_table(\"english\").values.tolist()\n",
    "stopwords=sum(stopwords , [])\n",
    "other_exclusions = [\"#ff\", \"ff\", \"rt\"]\n",
    "stopwords.extend(other_exclusions)\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df['text']\n",
    "\n",
    "def clean(text):\n",
    "    spaces = '\\s+'\n",
    "    urls = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mentions = '@[\\w\\-]+'\n",
    "    parsed_text = re.sub(spaces, ' ', text)\n",
    "    parsed_text = re.sub(urls, '', parsed_text)\n",
    "    parsed_text = re.sub(mentions, '', parsed_text)\n",
    "    return parsed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = \" \".join(re.split(\"[^a-zA-Z]*\", text.lower())).strip()\n",
    "    tokens = [stemmer.stem(t) for t in text.split()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_tokenize(text):\n",
    "    text = \" \".join(re.split(\"[^a-zA-Z.,!?]*\", tweet.lower())).strip()\n",
    "    return tweet.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=tokenize,\n",
    "    preprocessor=clean,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=stopwords,\n",
    "    use_idf=True,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=10000,\n",
    "    min_df=5,\n",
    "    max_df=0.501\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nchib\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'n', 'p', 'r', 'u', 'v', 'w'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "tfidf = vectorizer.fit_transform(tweets).toarray()\n",
    "vocab = {v:i for i, v in enumerate(vectorizer.get_feature_names())}\n",
    "idf_vals = vectorizer.idf_\n",
    "idf_dict = {i:idf_vals[i] for i in vocab.values()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = vectorizer.fit_transform(tweets).toarray()\n",
    "vocab = {v:i for i, v in enumerate(vectorizer.get_feature_names())}\n",
    "idf_vals = vectorizer.idf_\n",
    "idf_dict = {i:idf_vals[i] for i in vocab.values()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VS\n",
    "from textstat.textstat import *\n",
    "\n",
    "sentiment_analyzer = VS()\n",
    "\n",
    "def count_twitter_objs(text):\n",
    "    \n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "\n",
    "def other_features(text):\n",
    "    sentiment = sentiment_analyzer.polarity_scores(text)\n",
    "    \n",
    "    words = clean(text) #Get text only\n",
    "    \n",
    "    syllables = textstat.syllable_count(words) #count syllables in words\n",
    "    num_chars = sum(len(w) for w in words) #num chars in words\n",
    "    num_chars_total = len(text)\n",
    "    num_terms = len(text.split())\n",
    "    num_words = len(words.split())\n",
    "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "    num_unique_terms = len(set(words.split()))\n",
    "    \n",
    "    FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
    "    \n",
    "    FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
    "    \n",
    "    twitter_objs = count_twitter_objs(text) #Count #, @, and http://\n",
    "    retweet = 0\n",
    "    if \"rt\" in words:\n",
    "        retweet = 1\n",
    "    features = [FKRA, FRE,syllables, avg_syl, num_chars, num_chars_total, num_terms, num_words,\n",
    "                num_unique_terms, sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound'],\n",
    "                twitter_objs[2], twitter_objs[1],\n",
    "                twitter_objs[0], retweet]\n",
    "    \n",
    "    return features\n",
    "\n",
    "def get_feature_array(tweets):\n",
    "    feats=[]\n",
    "    for t in tweets:\n",
    "        feats.append(other_features(t))\n",
    "    return np.array(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = get_feature_array(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = np.concatenate([tfidf,feats],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102840, 5467)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features_names = [\"FKRA\", \"FRE\",\"num_syllables\", \"avg_syl_per_word\", \"num_chars\", \"num_chars_total\", \\\n",
    "                        \"num_terms\", \"num_words\", \"num_unique_words\", \"vader neg\",\"vader pos\",\"vader neu\", \"vader compound\", \\\n",
    "                        \"num_hashtags\", \"num_mentions\", \"num_urls\", \"is_retweet\"]\n",
    "\n",
    "variables = ['']*len(vocab)\n",
    "for k,v in vocab.items():\n",
    "    variables[v] = k\n",
    "\n",
    "feature_names = variables+other_features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4.1160710811663845,\n",
       " 1: 6.991853576484606,\n",
       " 2: 7.115979643898423,\n",
       " 3: 6.071679344584053,\n",
       " 4: 8.019141084330785,\n",
       " 5: 7.966218682876443,\n",
       " 6: 7.267930102816079,\n",
       " 7: 5.258168481774233,\n",
       " 8: 9.768340939140044,\n",
       " 9: 8.957410722923715,\n",
       " 10: 5.977074134847698,\n",
       " 11: 7.011500573868402,\n",
       " 12: 8.110112862536512,\n",
       " 13: 9.36287583103188,\n",
       " 14: 7.0985119508580325,\n",
       " 15: 6.823901959973604,\n",
       " 16: 9.496407223656403,\n",
       " 17: 7.696742574921235,\n",
       " 18: 10.749170192151771,\n",
       " 19: 10.46148811969999,\n",
       " 20: 4.127764540387636,\n",
       " 21: 8.413795276334735,\n",
       " 22: 7.9559621827092535,\n",
       " 23: 7.761806168268296,\n",
       " 24: 8.250470220231435,\n",
       " 25: 9.405435445450676,\n",
       " 26: 6.554477656095388,\n",
       " 27: 6.871048738399306,\n",
       " 28: 10.749170192151771,\n",
       " 29: 4.771551051865842,\n",
       " 30: 7.472025459159594,\n",
       " 31: 6.961199835393604,\n",
       " 32: 8.04111999104956,\n",
       " 33: 10.056023011591826,\n",
       " 34: 6.791536675471573,\n",
       " 35: 7.232661963978621,\n",
       " 36: 10.143034388581455,\n",
       " 37: 8.779729545686262,\n",
       " 38: 9.70771631732361,\n",
       " 39: 2.3501601164132566,\n",
       " 40: 5.4968967641051405,\n",
       " 41: 4.422424593792729,\n",
       " 42: 4.182732201454046,\n",
       " 43: 4.738720345132708,\n",
       " 44: 5.782835156952095,\n",
       " 45: 4.753962658764954,\n",
       " 46: 4.445940902076051,\n",
       " 47: 7.728745306007409,\n",
       " 48: 7.056132727889171,\n",
       " 49: 4.730171544850469,\n",
       " 50: 4.906108983634283,\n",
       " 51: 5.8063380014068775,\n",
       " 52: 8.90334350165344,\n",
       " 53: 4.266827659087494,\n",
       " 54: 5.206600311079289,\n",
       " 55: 6.688727181605351,\n",
       " 56: 5.562715918749127,\n",
       " 57: 8.09827840488951,\n",
       " 58: 8.985581599890413,\n",
       " 59: 5.29813173858607,\n",
       " 60: 8.930011748735602,\n",
       " 61: 8.756740027461564,\n",
       " 62: 8.110112862536512,\n",
       " 63: 8.019141084330785,\n",
       " 64: 9.70771631732361,\n",
       " 65: 8.570637747827703,\n",
       " 66: 7.80473121298533,\n",
       " 67: 10.595019512324512,\n",
       " 68: 10.23834456838578,\n",
       " 69: 8.146480506707388,\n",
       " 70: 8.85205020726589,\n",
       " 71: 9.496407223656403,\n",
       " 72: 6.238310685634921,\n",
       " 73: 7.170291633252163,\n",
       " 74: 9.97598030391829,\n",
       " 75: 9.70771631732361,\n",
       " 76: 10.749170192151771,\n",
       " 77: 5.438430305605177,\n",
       " 78: 8.779729545686262,\n",
       " 79: 9.13973227971767,\n",
       " 80: 6.843836174874421,\n",
       " 81: 8.533596476147356,\n",
       " 82: 7.613675976222621,\n",
       " 83: 8.413795276334735,\n",
       " 84: 7.3876380668820465,\n",
       " 85: 10.931491748945726,\n",
       " 86: 10.931491748945726,\n",
       " 87: 8.85205020726589,\n",
       " 88: 8.413795276334735,\n",
       " 89: 8.90334350165344,\n",
       " 90: 8.075021542725242,\n",
       " 91: 8.04111999104956,\n",
       " 92: 9.65055790348366,\n",
       " 93: 9.173633831393351,\n",
       " 94: 4.423020718996671,\n",
       " 95: 8.00833016822657,\n",
       " 96: 8.446585099157726,\n",
       " 97: 5.402856627335479,\n",
       " 98: 7.886969311222303,\n",
       " 99: 8.62890665595168,\n",
       " 100: 7.5236498245649015,\n",
       " 101: 6.17962718380683,\n",
       " 102: 9.832879460277615,\n",
       " 103: 8.930011748735602,\n",
       " 104: 8.210196321093495,\n",
       " 105: 7.658127738793455,\n",
       " 106: 7.896538762238453,\n",
       " 107: 6.942507702381451,\n",
       " 108: 7.309821044525239,\n",
       " 109: 8.463392217474105,\n",
       " 110: 7.543717387615711,\n",
       " 111: 2.5909880044718134,\n",
       " 112: 7.156434598590737,\n",
       " 113: 3.055232866642499,\n",
       " 114: 5.706820922565988,\n",
       " 115: 6.9996661162214,\n",
       " 116: 5.272009533186104,\n",
       " 117: 7.031541324751848,\n",
       " 118: 6.541993099433143,\n",
       " 119: 8.756740027461564,\n",
       " 120: 7.370445666341674,\n",
       " 121: 5.306031241064995,\n",
       " 122: 5.183373460469473,\n",
       " 123: 7.578085031119919,\n",
       " 124: 10.46148811969999,\n",
       " 125: 5.22438148419685,\n",
       " 126: 7.7451391157830844,\n",
       " 127: 8.756740027461564,\n",
       " 128: 7.681117257018154,\n",
       " 129: 9.97598030391829,\n",
       " 130: 7.795997533016576,\n",
       " 131: 6.4118794513192805,\n",
       " 132: 9.545197387825835,\n",
       " 133: 9.44988720802151,\n",
       " 134: 7.517049140533549,\n",
       " 135: 10.343705084043606,\n",
       " 136: 9.405435445450676,\n",
       " 137: 8.930011748735602,\n",
       " 138: 10.749170192151771,\n",
       " 139: 10.23834456838578,\n",
       " 140: 9.405435445450676,\n",
       " 141: 8.930011748735602,\n",
       " 142: 9.768340939140044,\n",
       " 143: 8.110112862536512,\n",
       " 144: 5.263681934748342,\n",
       " 145: 8.27824978433851,\n",
       " 146: 8.6091040286555,\n",
       " 147: 6.57222210139446,\n",
       " 148: 8.463392217474105,\n",
       " 149: 8.87736801525018,\n",
       " 150: 8.09827840488951,\n",
       " 151: 7.031541324751848,\n",
       " 152: 10.143034388581455,\n",
       " 153: 9.65055790348366,\n",
       " 154: 8.551945614815551,\n",
       " 155: 7.635654882941396,\n",
       " 156: 8.292434419330466,\n",
       " 157: 8.171481808912805,\n",
       " 158: 8.62890665595168,\n",
       " 159: 9.832879460277615,\n",
       " 160: 8.6091040286555,\n",
       " 161: 3.178211608982761,\n",
       " 162: 7.3876380668820465,\n",
       " 163: 5.300997070059356,\n",
       " 164: 4.062685220102163,\n",
       " 165: 7.736908616646569,\n",
       " 166: 6.830502644004956,\n",
       " 167: 6.972585157618729,\n",
       " 168: 5.170069494843109,\n",
       " 169: 9.208725151204622,\n",
       " 170: 7.712615924077524,\n",
       " 171: 5.477881497991653,\n",
       " 172: 6.39674402725418,\n",
       " 173: 7.987052769779285,\n",
       " 174: 7.405131224329564,\n",
       " 175: 5.764422669007643,\n",
       " 176: 8.366542391484188,\n",
       " 177: 6.460996466284236,\n",
       " 178: 9.70771631732361,\n",
       " 179: 9.36287583103188,\n",
       " 180: 4.382699744420333,\n",
       " 181: 7.831399460067492,\n",
       " 182: 7.536983355434367,\n",
       " 183: 6.312418657788642,\n",
       " 184: 7.770245036914161,\n",
       " 185: 6.8919554232186195,\n",
       " 186: 7.056132727889171,\n",
       " 187: 6.318353393308457,\n",
       " 188: 8.827357594675519,\n",
       " 189: 6.83381939663095,\n",
       " 190: 7.831399460067492,\n",
       " 191: 6.375511807148405,\n",
       " 192: 7.987052769779285,\n",
       " 193: 9.65055790348366,\n",
       " 194: 7.497504544460579,\n",
       " 195: 7.472025459159594,\n",
       " 196: 9.044422099913346,\n",
       " 197: 7.342432630114,\n",
       " 198: 9.901872331764567,\n",
       " 199: 10.343705084043606,\n",
       " 200: 5.508305400351819,\n",
       " 201: 9.901872331764567,\n",
       " 202: 8.985581599890413,\n",
       " 203: 7.262815002149308,\n",
       " 204: 10.23834456838578,\n",
       " 205: 9.322053836511625,\n",
       " 206: 8.413795276334735,\n",
       " 207: 7.503977058966196,\n",
       " 208: 9.901872331764567,\n",
       " 209: 7.665732338178675,\n",
       " 210: 9.208725151204622,\n",
       " 211: 8.223441547843516,\n",
       " 212: 7.1796374956704,\n",
       " 213: 7.673395210924244,\n",
       " 214: 9.044422099913346,\n",
       " 215: 8.184220834690233,\n",
       " 216: 10.595019512324512,\n",
       " 217: 10.931491748945726,\n",
       " 218: 8.90334350165344,\n",
       " 219: 3.2728865792753536,\n",
       " 220: 7.133757889919707,\n",
       " 221: 6.373413170491484,\n",
       " 222: 4.693167123906218,\n",
       " 223: 7.896538762238453,\n",
       " 224: 7.517049140533549,\n",
       " 225: 6.140672216071005,\n",
       " 226: 4.666570836649944,\n",
       " 227: 9.832879460277615,\n",
       " 228: 6.060885099453173,\n",
       " 229: 7.370445666341674,\n",
       " 230: 5.740759593077626,\n",
       " 231: 7.849581779150682,\n",
       " 232: 10.931491748945726,\n",
       " 233: 6.383950675794271,\n",
       " 234: 5.665697574103249,\n",
       " 235: 7.712615924077524,\n",
       " 236: 6.162503477728239,\n",
       " 237: 10.46148811969999,\n",
       " 238: 8.236864568175656,\n",
       " 239: 2.7714307488470147,\n",
       " 240: 5.907611228099449,\n",
       " 241: 5.916864433579932,\n",
       " 242: 5.386314304466163,\n",
       " 243: 6.1557352623821,\n",
       " 244: 5.991278919146016,\n",
       " 245: 4.485454519622551,\n",
       " 246: 4.259205670968435,\n",
       " 247: 7.896538762238453,\n",
       " 248: 7.23762475332075,\n",
       " 249: 5.438430305605177,\n",
       " 250: 5.059373959470309,\n",
       " 251: 6.181355792707448,\n",
       " 252: 9.208725151204622,\n",
       " 253: 5.1600506258157095,\n",
       " 254: 5.568323410078072,\n",
       " 255: 8.366542391484188,\n",
       " 256: 5.7329947176799,\n",
       " 257: 9.97598030391829,\n",
       " 258: 8.110112862536512,\n",
       " 259: 6.360913007727253,\n",
       " 260: 10.595019512324512,\n",
       " 261: 9.97598030391829,\n",
       " 262: 7.620948735551701,\n",
       " 263: 6.957433352598127,\n",
       " 264: 10.749170192151771,\n",
       " 265: 10.46148811969999,\n",
       " 266: 10.143034388581455,\n",
       " 267: 5.256108748811222,\n",
       " 268: 9.36287583103188,\n",
       " 269: 8.930011748735602,\n",
       " 270: 6.9879700764582084,\n",
       " 271: 8.90334350165344,\n",
       " 272: 9.322053836511625,\n",
       " 273: 6.942507702381451,\n",
       " 274: 6.7851874477929135,\n",
       " 275: 10.749170192151771,\n",
       " 276: 9.768340939140044,\n",
       " 277: 7.635654882941396,\n",
       " 278: 7.86810082691792,\n",
       " 279: 9.322053836511625,\n",
       " 280: 7.831399460067492,\n",
       " 281: 8.90334350165344,\n",
       " 282: 10.595019512324512,\n",
       " 283: 8.87736801525018,\n",
       " 284: 6.481806465798029,\n",
       " 285: 8.71228826489073,\n",
       " 286: 9.545197387825835,\n",
       " 287: 8.6091040286555,\n",
       " 288: 8.756740027461564,\n",
       " 289: 10.595019512324512,\n",
       " 290: 9.70771631732361,\n",
       " 291: 8.197124239526142,\n",
       " 292: 10.46148811969999,\n",
       " 293: 10.23834456838578,\n",
       " 294: 8.71228826489073,\n",
       " 295: 9.496407223656403,\n",
       " 296: 9.832879460277615,\n",
       " 297: 9.70771631732361,\n",
       " 298: 10.056023011591826,\n",
       " 299: 7.7787557265820695,\n",
       " 300: 9.70771631732361,\n",
       " 301: 10.749170192151771,\n",
       " 302: 9.97598030391829,\n",
       " 303: 10.749170192151771,\n",
       " 304: 9.97598030391829,\n",
       " 305: 9.97598030391829,\n",
       " 306: 10.23834456838578,\n",
       " 307: 10.343705084043606,\n",
       " 308: 10.343705084043606,\n",
       " 309: 5.08159076615953,\n",
       " 310: 8.446585099157726,\n",
       " 311: 8.497878393545275,\n",
       " 312: 6.685857739177399,\n",
       " 313: 9.405435445450676,\n",
       " 314: 9.901872331764567,\n",
       " 315: 8.551945614815551,\n",
       " 316: 6.697385244348466,\n",
       " 317: 9.832879460277615,\n",
       " 318: 8.90334350165344,\n",
       " 319: 7.309821044525239,\n",
       " 320: 8.397794934988294,\n",
       " 321: 9.322053836511625,\n",
       " 322: 7.370445666341674,\n",
       " 323: 7.0478682180392775,\n",
       " 324: 9.70771631732361,\n",
       " 325: 9.075193758580099,\n",
       " 326: 10.23834456838578,\n",
       " 327: 4.132435886886929,\n",
       " 328: 8.397794934988294,\n",
       " 329: 7.86810082691792,\n",
       " 330: 5.764422669007643,\n",
       " 331: 8.463392217474105,\n",
       " 332: 8.87736801525018,\n",
       " 333: 5.903671630095369,\n",
       " 334: 6.381834272887893,\n",
       " 335: 10.595019512324512,\n",
       " 336: 6.714929553999376,\n",
       " 337: 6.703199214213886,\n",
       " 338: 6.871048738399306,\n",
       " 339: 7.5104917399873905,\n",
       " 340: 6.935127595083828,\n",
       " 341: 5.95062861318314,\n",
       " 342: 9.44988720802151,\n",
       " 343: 8.413795276334735,\n",
       " 344: 2.583048625013366,\n",
       " 345: 5.261610825965206,\n",
       " 346: 5.6493037643275725,\n",
       " 347: 5.318363642557655,\n",
       " 348: 5.062194835811951,\n",
       " 349: 6.2586629144838195,\n",
       " 350: 4.98032849861127,\n",
       " 351: 4.719687577856268,\n",
       " 352: 7.453333326147441,\n",
       " 353: 7.217919682241417,\n",
       " 354: 5.168183294975497,\n",
       " 355: 4.429301583072085,\n",
       " 356: 5.3427460842778824,\n",
       " 357: 9.322053836511625,\n",
       " 358: 4.5216458684630325,\n",
       " 359: 5.422913456914492,\n",
       " 360: 6.791536675471573,\n",
       " 361: 5.51628063092619,\n",
       " 362: 7.896538762238453,\n",
       " 363: 10.143034388581455,\n",
       " 364: 5.090850091572327,\n",
       " 365: 9.245092795375497,\n",
       " 366: 8.122089053583228,\n",
       " 367: 7.571116361803825,\n",
       " 368: 7.089891207814125,\n",
       " 369: 9.405435445450676,\n",
       " 370: 8.086582365126318,\n",
       " 371: 7.484683856031518,\n",
       " 372: 10.931491748945726,\n",
       " 373: 9.901872331764567,\n",
       " 374: 8.146480506707388,\n",
       " 375: 8.669728650471935,\n",
       " 376: 9.322053836511625,\n",
       " 377: 6.254931566870961,\n",
       " 378: 7.156434598590737,\n",
       " 379: 10.46148811969999,\n",
       " 380: 9.10694245689468,\n",
       " 381: 5.740759593077626,\n",
       " 382: 9.13973227971767,\n",
       " 383: 9.075193758580099,\n",
       " 384: 7.441063233555627,\n",
       " 385: 10.056023011591826,\n",
       " 386: 9.36287583103188,\n",
       " 387: 8.985581599890413,\n",
       " 388: 7.55049707460109,\n",
       " 389: 10.931491748945726,\n",
       " 390: 9.075193758580099,\n",
       " 391: 7.376143687456311,\n",
       " 392: 9.13973227971767,\n",
       " 393: 7.7787557265820695,\n",
       " 394: 8.827357594675519,\n",
       " 395: 9.70771631732361,\n",
       " 396: 9.97598030391829,\n",
       " 397: 2.1016799997876756,\n",
       " 398: 5.477881497991653,\n",
       " 399: 5.7057450752325245,\n",
       " 400: 3.321530444915297,\n",
       " 401: 5.487343934186149,\n",
       " 402: 6.181355792707448,\n",
       " 403: 4.859369298820289,\n",
       " 404: 3.7535566726479495,\n",
       " 405: 7.416965681976567,\n",
       " 406: 6.624727598772391,\n",
       " 407: 4.795061431587557,\n",
       " 408: 4.356973944074872,\n",
       " 409: 5.433504187269121,\n",
       " 410: 9.173633831393351,\n",
       " 411: 4.645121284296643,\n",
       " 412: 5.034887482861704,\n",
       " 413: 6.90971787955846,\n",
       " 414: 5.309642657052211,\n",
       " 415: 9.901872331764567,\n",
       " 416: 9.245092795375497,\n",
       " 417: 3.0785084881948355,\n",
       " 418: 7.299182646320183,\n",
       " 419: 6.17962718380683,\n",
       " 420: 4.888383968685905,\n",
       " 421: 6.544477572760805,\n",
       " 422: 7.478334628352859,\n",
       " 423: 6.96498055823351,\n",
       " 424: 5.787491742782046,\n",
       " 425: 9.245092795375497,\n",
       " 426: 8.589685942798399,\n",
       " 427: 4.955140839647791,\n",
       " 428: 4.0175556108885075,\n",
       " 429: 6.427247481547594,\n",
       " 430: 10.595019512324512,\n",
       " 431: 6.44735989133469,\n",
       " 432: 6.7479160529956825,\n",
       " 433: 5.8790749208345146,\n",
       " 434: 7.428941873023282,\n",
       " 435: 9.545197387825835,\n",
       " 436: 8.669728650471935,\n",
       " 437: 7.1843433867078135,\n",
       " 438: 9.65055790348366,\n",
       " 439: 9.768340939140044,\n",
       " 440: 9.70771631732361,\n",
       " 441: 10.056023011591826,\n",
       " 442: 9.13973227971767,\n",
       " 443: 10.23834456838578,\n",
       " 444: 10.23834456838578,\n",
       " 445: 10.749170192151771,\n",
       " 446: 10.749170192151771,\n",
       " 447: 8.366542391484188,\n",
       " 448: 2.214006115414297,\n",
       " 449: 5.606532451451268,\n",
       " 450: 6.287100849804353,\n",
       " 451: 3.721559951361355,\n",
       " 452: 5.490807141110767,\n",
       " 453: 6.367143557477889,\n",
       " 454: 5.020695104905198,\n",
       " 455: 2.992119050119757,\n",
       " 456: 7.736908616646569,\n",
       " 457: 7.283434289352044,\n",
       " 458: 5.701453223150983,\n",
       " 459: 5.143981058758812,\n",
       " 460: 6.032160524408144,\n",
       " 461: 9.075193758580099,\n",
       " 462: 5.872701412962423,\n",
       " 463: 5.04984206784495,\n",
       " 464: 7.75343791859778,\n",
       " 465: 5.596842453150298,\n",
       " 466: 9.70771631732361,\n",
       " 467: 10.056023011591826,\n",
       " 468: 3.0755595492271115,\n",
       " 469: 6.913308547689189,\n",
       " 470: 6.45188478593298,\n",
       " 471: 4.607849889499411,\n",
       " 472: 7.428941873023282,\n",
       " 473: 7.712615924077524,\n",
       " 474: 6.41406047726564,\n",
       " 475: 4.884119569899447,\n",
       " 476: 9.36287583103188,\n",
       " 477: 8.210196321093495,\n",
       " 478: 4.369612786660095,\n",
       " 479: 6.386071567363408,\n",
       " 480: 6.772608665586054,\n",
       " 481: 9.901872331764567,\n",
       " 482: 5.821916506994566,\n",
       " 483: 5.30027996712436,\n",
       " 484: 8.00833016822657,\n",
       " 485: 6.41406047726564,\n",
       " 486: 10.343705084043606,\n",
       " 487: 10.23834456838578,\n",
       " 488: 2.907480746122883,\n",
       " 489: 5.673996376917944,\n",
       " 490: 5.129373373568662,\n",
       " 491: 5.059937498510301,\n",
       " 492: 5.396522481058686,\n",
       " 493: 5.6543980188493155,\n",
       " 494: 5.715469625124519,\n",
       " 495: 4.958191172465415,\n",
       " 496: 7.7787557265820695,\n",
       " 497: 6.6033934562973995,\n",
       " 498: 5.979898995483253,\n",
       " 499: 5.23305688061612,\n",
       " 500: 6.1241973788675,\n",
       " 501: 8.957410722923715,\n",
       " 502: 5.425347535195372,\n",
       " 503: 5.770140237470846,\n",
       " 504: 6.238310685634921,\n",
       " 505: 5.836515306415719,\n",
       " 506: 10.931491748945726,\n",
       " 507: 10.23834456838578,\n",
       " 508: 4.191208823907337,\n",
       " 509: 8.146480506707388,\n",
       " 510: 7.849581779150682,\n",
       " 511: 6.0203085338211295,\n",
       " 512: 8.223441547843516,\n",
       " 513: 9.97598030391829,\n",
       " 514: 7.613675976222621,\n",
       " 515: 6.11282438869523,\n",
       " 516: 9.901872331764567,\n",
       " 517: 10.46148811969999,\n",
       " 518: 5.73520710796284,\n",
       " 519: 6.5469682340732565,\n",
       " 520: 7.393435184566373,\n",
       " 521: 5.994144250619302,\n",
       " 522: 6.735794692463338,\n",
       " 523: 9.832879460277615,\n",
       " 524: 8.413795276334735,\n",
       " 525: 7.849581779150682,\n",
       " 526: 8.030070154862976,\n",
       " 527: 2.998986029893934,\n",
       " 528: 6.709047184096309,\n",
       " 529: 6.0456641054428175,\n",
       " 530: 4.093086548098382,\n",
       " 531: 6.5054482288550695,\n",
       " 532: 7.585102603778565,\n",
       " 533: 6.41406047726564,\n",
       " 534: 4.681130480817716,\n",
       " 535: 8.756740027461564,\n",
       " 536: 7.896538762238453,\n",
       " 537: 6.346524270275154,\n",
       " 538: 5.78516073939557,\n",
       " 539: 5.9262040611760645,\n",
       " 540: 5.903671630095369,\n",
       " 541: 5.507423177092129,\n",
       " 542: 7.770245036914161,\n",
       " 543: 6.4206322424288755,\n",
       " 544: 10.595019512324512,\n",
       " 545: 5.867631693612172,\n",
       " 546: 2.9714473909011234,\n",
       " 547: 7.115979643898423,\n",
       " 548: 7.133757889919707,\n",
       " 549: 4.296595613523731,\n",
       " 550: 7.203391581678508,\n",
       " 551: 6.9996661162214,\n",
       " 552: 6.931457866194866,\n",
       " 553: 5.885489311012178,\n",
       " 554: 9.36287583103188,\n",
       " 555: 9.36287583103188,\n",
       " 556: 4.4956619447720225,\n",
       " 557: 4.717283730544873,\n",
       " 558: 6.109598579446347,\n",
       " 559: 4.673824161063086,\n",
       " 560: 7.658127738793455,\n",
       " 561: 9.10694245689468,\n",
       " 562: 8.210196321093495,\n",
       " 563: 6.665998930527795,\n",
       " 564: 5.573020459577942,\n",
       " 565: 9.901872331764567,\n",
       " 566: 9.70771631732361,\n",
       " 567: 6.014434801809036,\n",
       " 568: 10.46148811969999,\n",
       " 569: 10.23834456838578,\n",
       " 570: 9.901872331764567,\n",
       " 571: 7.094192289713516,\n",
       " 572: 9.44988720802151,\n",
       " 573: 10.23834456838578,\n",
       " 574: 10.343705084043606,\n",
       " 575: 9.36287583103188,\n",
       " 576: 10.46148811969999,\n",
       " 577: 10.749170192151771,\n",
       " 578: 5.328635192879485,\n",
       " 579: 8.264263542363771,\n",
       " 580: 9.36287583103188,\n",
       " 581: 7.133757889919707,\n",
       " 582: 9.36287583103188,\n",
       " 583: 9.545197387825835,\n",
       " 584: 7.2476248366553335,\n",
       " 585: 6.688727181605351,\n",
       " 586: 9.65055790348366,\n",
       " 587: 8.827357594675519,\n",
       " 588: 8.497878393545275,\n",
       " 589: 9.36287583103188,\n",
       " 590: 7.10285035245663,\n",
       " 591: 9.208725151204622,\n",
       " 592: 9.65055790348366,\n",
       " 593: 9.832879460277615,\n",
       " 594: 10.46148811969999,\n",
       " 595: 8.480486650833406,\n",
       " 596: 10.343705084043606,\n",
       " 597: 10.143034388581455,\n",
       " 598: 10.46148811969999,\n",
       " 599: 7.704647754428348,\n",
       " 600: 8.985581599890413,\n",
       " 601: 9.768340939140044,\n",
       " 602: 9.13973227971767,\n",
       " 603: 10.749170192151771,\n",
       " 604: 10.749170192151771,\n",
       " 605: 10.931491748945726,\n",
       " 606: 10.595019512324512,\n",
       " 607: 10.749170192151771,\n",
       " 608: 2.3685224548929042,\n",
       " 609: 5.710055426733646,\n",
       " 610: 5.3169048530939955,\n",
       " 611: 3.5919540535380508,\n",
       " 612: 6.946218281777987,\n",
       " 613: 6.688727181605351,\n",
       " 614: 5.706820922565988,\n",
       " 615: 3.973233487790482,\n",
       " 616: 7.9559621827092535,\n",
       " 617: 6.184822000683934,\n",
       " 618: 4.804185978926331,\n",
       " 619: 5.8195039605891825,\n",
       " 620: 6.916912155192487,\n",
       " 621: 4.528911422220764,\n",
       " 622: 4.105814580999196,\n",
       " 623: 7.7787557265820695,\n",
       " 624: 6.920528795662676,\n",
       " 625: 7.9559621827092535,\n",
       " 626: 9.545197387825835,\n",
       " 627: 2.244792097782377,\n",
       " 628: 6.823901959973604,\n",
       " 629: 5.758737605373034,\n",
       " 630: 4.342840412423709,\n",
       " 631: 6.369229063968911,\n",
       " 632: 6.9957522169002635,\n",
       " 633: 3.9408669921412938,\n",
       " 634: 4.247880521611382,\n",
       " 635: 8.957410722923715,\n",
       " 636: 4.91241203480477,\n",
       " 637: 4.5907797737278075,\n",
       " 638: 4.323491123649639,\n",
       " 639: 5.565515733923874,\n",
       " 640: 9.405435445450676,\n",
       " 641: 4.082425466312268,\n",
       " 642: 3.9980687232150105,\n",
       " 643: 6.942507702381451,\n",
       " 644: 7.015476722248042,\n",
       " 645: 10.143034388581455,\n",
       " 646: 9.10694245689468,\n",
       " 647: 1.8118860404320494,\n",
       " 648: 4.45544288927698,\n",
       " 649: 4.663911765757428,\n",
       " 650: 4.175257277604831,\n",
       " 651: 4.731388336726416,\n",
       " 652: 5.444208282885065,\n",
       " 653: 4.155440960961016,\n",
       " 654: 4.10472962917312,\n",
       " 655: 6.87796918124388,\n",
       " 656: 4.7929011369474495,\n",
       " 657: 3.8670746599502115,\n",
       " 658: 3.258454691644444,\n",
       " 659: 4.084548609360345,\n",
       " 660: 7.704647754428348,\n",
       " 661: 3.5588710185739765,\n",
       " 662: 4.838825321328776,\n",
       " 663: 4.827591772507955,\n",
       " 664: 5.01475074803368,\n",
       " 665: 5.284632421689145,\n",
       " 666: 6.991853576484606,\n",
       " 667: 2.2080000913540854,\n",
       " 668: 6.240143866716582,\n",
       " 669: 5.49428238353107,\n",
       " 670: 4.6057001215629185,\n",
       " 671: 4.98293470284902,\n",
       " 672: 6.316371232104466,\n",
       " 673: 4.790314928609417,\n",
       " 674: 4.385567541051691,\n",
       " 675: 8.264263542363771,\n",
       " 676: 6.972585157618729,\n",
       " 677: 4.875176229518127,\n",
       " 678: 5.934279475181611,\n",
       " 679: 6.442855379213586,\n",
       " 680: 9.901872331764567,\n",
       " 681: 3.2996721867689214,\n",
       " 682: 3.593253598880136,\n",
       " 683: 7.115979643898423,\n",
       " 684: 6.527214505337024,\n",
       " 685: 8.570637747827703,\n",
       " 686: 10.143034388581455,\n",
       " 687: 2.8681769008537286,\n",
       " 688: 6.585092291914995,\n",
       " 689: 7.094192289713516,\n",
       " 690: 4.186961531066554,\n",
       " 691: 6.706118924317221,\n",
       " 692: 6.114441203922135,\n",
       " 693: 6.122564725443614,\n",
       " 694: 4.41293460560788,\n",
       " 695: 9.014569136763665,\n",
       " 696: 8.236864568175656,\n",
       " 697: 5.51095674967344,\n",
       " 698: 5.431050198307554,\n",
       " 699: 6.6603966749791255,\n",
       " 700: 10.343705084043606,\n",
       " 701: 4.759373702144486,\n",
       " 702: 5.365439947755604,\n",
       " 703: 7.051991935223139,\n",
       " 704: 7.027500915214843,\n",
       " 705: 10.343705084043606,\n",
       " 706: 9.282833123358344,\n",
       " 707: 2.014127437882433,\n",
       " 708: 5.911566407942377,\n",
       " 709: 6.369229063968911,\n",
       " 710: 2.6701719334666167,\n",
       " 711: 6.488840492455409,\n",
       " 712: 6.775738558594981,\n",
       " 713: 5.383194177129919,\n",
       " 714: 3.431625833581415,\n",
       " 715: 8.086582365126318,\n",
       " 716: 7.023476764915118,\n",
       " 717: 5.65133835302536,\n",
       " 718: 4.851558553850135,\n",
       " 719: 5.391798062822419,\n",
       " 720: 8.90334350165344,\n",
       " 721: 5.005632958935737,\n",
       " 722: 4.7120951337917365,\n",
       " 723: 5.129373373568662,\n",
       " 724: 4.879402580021308,\n",
       " 725: 9.44988720802151,\n",
       " 726: 9.596490682213386,\n",
       " 727: 1.8888365698305085,\n",
       " 728: 5.426160213013363,\n",
       " 729: 4.560906069069182,\n",
       " 730: 4.13982094898439,\n",
       " 731: 4.684610089973238,\n",
       " 732: 4.6673318716942855,\n",
       " 733: 4.661259746775537,\n",
       " 734: 4.713290115013404,\n",
       " 735: 6.537042594273287,\n",
       " 736: 6.099983120746905,\n",
       " 737: 4.290048516679176,\n",
       " 738: 2.663529443607016,\n",
       " 739: 5.327898001544956,\n",
       " 740: 8.589685942798399,\n",
       " 741: 4.149299692938934,\n",
       " 742: 5.4286022166689145,\n",
       " 743: 5.616317265331266,\n",
       " 744: 5.1155717743526745,\n",
       " 745: 7.347972810489615,\n",
       " 746: 7.650580533158072,\n",
       " 747: 4.337899419664966,\n",
       " 748: 6.946218281777987,\n",
       " 749: 7.915956848095555,\n",
       " 750: 6.302605036340318,\n",
       " 751: 9.10694245689468,\n",
       " 752: 9.832879460277615,\n",
       " 753: 7.80473121298533,\n",
       " 754: 6.590287108792099,\n",
       " 755: 9.832879460277615,\n",
       " 756: 7.987052769779285,\n",
       " 757: 9.245092795375497,\n",
       " 758: 7.90620067315019,\n",
       " 759: 8.756740027461564,\n",
       " 760: 7.585102603778565,\n",
       " 761: 5.05881073782771,\n",
       " 762: 9.70771631732361,\n",
       " 763: 9.208725151204622,\n",
       " 764: 10.343705084043606,\n",
       " 765: 3.4401809660337377,\n",
       " 766: 7.10285035245663,\n",
       " 767: 7.673395210924244,\n",
       " 768: 4.678432464149281,\n",
       " 769: 6.590287108792099,\n",
       " 770: 7.736908616646569,\n",
       " 771: 6.383950675794271,\n",
       " 772: 4.7728192828538365,\n",
       " 773: 8.497878393545275,\n",
       " 774: 8.00833016822657,\n",
       " 775: 7.007540172652305,\n",
       " 776: 5.4286022166689145,\n",
       " 777: 7.42293584896307,\n",
       " 778: 10.931491748945726,\n",
       " 779: 6.984101599680288,\n",
       " 780: 6.608684473931815,\n",
       " 781: 8.6091040286555,\n",
       " 782: 6.90971787955846,\n",
       " 783: 10.931491748945726,\n",
       " 784: 10.595019512324512,\n",
       " 785: 1.9760436265983328,\n",
       " 786: 5.545163505074975,\n",
       " 787: 5.587245450509289,\n",
       " 788: 3.620807909507421,\n",
       " 789: 4.55170825256455,\n",
       " 790: 6.2183644214525415,\n",
       " 791: 5.010449666134289,\n",
       " 792: 3.4016557378375034,\n",
       " 793: 7.688899397460209,\n",
       " 794: 5.198797930795104,\n",
       " 795: 3.1722189534322016,\n",
       " 796: 4.913872244360892,\n",
       " 797: 4.901768489720653,\n",
       " 798: 8.446585099157726,\n",
       " 799: 5.362384177616126,\n",
       " 800: 5.3427460842778824,\n",
       " 801: 5.330850033209038,\n",
       " 802: 5.241808198669026,\n",
       " 803: 7.822430790084731,\n",
       " 804: 8.430055797206514,\n",
       " 805: 4.45544288927698,\n",
       " 806: 3.9456649345434327,\n",
       " 807: 3.0356833718625427,\n",
       " 808: 4.386429486227884,\n",
       " 809: 4.445026128418724,\n",
       " 810: 3.5233248845464704,\n",
       " 811: 3.0982085327369515,\n",
       " 812: 5.751957918387656,\n",
       " 813: 5.329372928066024,\n",
       " 814: 4.076926298477707,\n",
       " 815: 3.979910990423559,\n",
       " 816: 4.5272555185471415,\n",
       " 817: 7.673395210924244,\n",
       " 818: 4.12046765892336,\n",
       " 819: 3.9175762741351976,\n",
       " 820: 5.832845577526756,\n",
       " 821: 4.11409891004398,\n",
       " 822: 8.184220834690233,\n",
       " 823: 7.161032307839366,\n",
       " 824: 2.3616681574662888,\n",
       " 825: 6.445105098947601,\n",
       " 826: 5.924864476247008,\n",
       " 827: 3.9571999461633443,\n",
       " 828: 6.310448213801344,\n",
       " 829: 6.8745029732673935,\n",
       " 830: 5.038191450624975,\n",
       " 831: 4.27425121807393,\n",
       " 832: 8.734267171609506,\n",
       " 833: 6.927801554991755,\n",
       " 834: 3.760142193040897,\n",
       " 835: 5.417256876175219,\n",
       " 836: 5.274102313859235,\n",
       " 837: 9.768340939140044,\n",
       " 838: 3.9523464738769154,\n",
       " 839: 4.739129259470854,\n",
       " 840: 7.7451391157830844,\n",
       " 841: 6.0888807069426,\n",
       " 842: 9.70771631732361,\n",
       " 843: 10.056023011591826,\n",
       " 844: 5.368505084254981,\n",
       " 845: 9.832879460277615,\n",
       " 846: 10.931491748945726,\n",
       " 847: 10.23834456838578,\n",
       " 848: 10.931491748945726,\n",
       " 849: 10.931491748945726,\n",
       " 850: 10.46148811969999,\n",
       " 851: 10.595019512324512,\n",
       " 852: 5.420485288987338,\n",
       " 853: 4.124662388553549,\n",
       " 854: 4.147260956249086,\n",
       " 855: 2.5206818182349986,\n",
       " 856: 4.015569907297195,\n",
       " 857: 4.516394789774131,\n",
       " 858: 3.510433916322705,\n",
       " 859: 3.017385679721784,\n",
       " 860: 6.193540451723815,\n",
       " 861: 5.334552369907573,\n",
       " 862: 3.987597423347715,\n",
       " 863: 3.2309249662906976,\n",
       " 864: 4.336531243230445,\n",
       " 865: 7.688899397460209,\n",
       " 866: 3.9955378156049095,\n",
       " 867: 4.020342236895573,\n",
       " 868: 4.777058373559604,\n",
       " 869: 4.185784921917987,\n",
       " 870: 8.446585099157726,\n",
       " 871: 7.491073654130289,\n",
       " 872: 2.4473177399867225,\n",
       " 873: 5.531520728671189,\n",
       " 874: 4.98607114033915,\n",
       " 875: 5.247911981607044,\n",
       " 876: 5.48303172396797,\n",
       " 877: 5.682364626588461,\n",
       " 878: 5.2377596101430255,\n",
       " 879: 4.873303569794835,\n",
       " 880: 7.849581779150682,\n",
       " 881: 6.4228324633384775,\n",
       " 882: 5.383973296764189,\n",
       " 883: 4.4998386576711935,\n",
       " 884: 4.152251892199016,\n",
       " 885: 9.70771631732361,\n",
       " 886: 3.847097696305132,\n",
       " 887: 6.2419804145238835,\n",
       " 888: 7.381874362165297,\n",
       " 889: 5.932929036083739,\n",
       " 890: 8.649109363269199,\n",
       " 891: 9.10694245689468,\n",
       " 892: 2.749547542628006,\n",
       " 893: 8.134210414115572,\n",
       " 894: 7.858798434255606,\n",
       " 895: 3.0264926756837673,\n",
       " 896: 9.208725151204622,\n",
       " 897: 8.122089053583228,\n",
       " 898: 8.551945614815551,\n",
       " 899: 4.386716966465597,\n",
       " 900: 10.056023011591826,\n",
       " 901: 8.985581599890413,\n",
       " 902: 6.522336446883592,\n",
       " 903: 6.881447445620204,\n",
       " 904: 7.997634879109822,\n",
       " 905: 7.5236498245649015,\n",
       " 906: 8.33623704198886,\n",
       " 907: 9.832879460277615,\n",
       " 908: 8.533596476147356,\n",
       " 909: 2.3274238565462646,\n",
       " 910: 6.190043944665086,\n",
       " 911: 5.682364626588461,\n",
       " 912: 3.9291538274776405,\n",
       " 913: 5.720913296705696,\n",
       " 914: 6.616673863965294,\n",
       " 915: 3.803316624570975,\n",
       " 916: 3.798674759493475,\n",
       " 917: 7.673395210924244,\n",
       " 918: 7.142766959862073,\n",
       " 919: 5.772436449731196,\n",
       " 920: 4.734233288858647,\n",
       " 921: 6.04717582152814,\n",
       " 922: 9.545197387825835,\n",
       " 923: 4.270148648217152,\n",
       " 924: 5.554363201973399,\n",
       " 925: 7.011500573868402,\n",
       " 926: 6.099983120746905,\n",
       " 927: 9.545197387825835,\n",
       " 928: 9.075193758580099,\n",
       " 929: 3.6173384638068233,\n",
       " 930: 7.085608546022124,\n",
       " 931: 5.366205351543449,\n",
       " 932: 5.941059162166989,\n",
       " 933: 7.331443508538405,\n",
       " 934: 7.7787557265820695,\n",
       " 935: 6.801136749200592,\n",
       " 936: 5.574905474273713,\n",
       " 937: 9.173633831393351,\n",
       " 938: 9.245092795375497,\n",
       " 939: 7.370445666341674,\n",
       " 940: 6.913308547689189,\n",
       " 941: 5.0244963584641935,\n",
       " 942: 9.97598030391829,\n",
       " 943: 6.253071101218041,\n",
       " 944: 6.720846731027464,\n",
       " 945: 8.446585099157726,\n",
       " 946: 6.9879700764582084,\n",
       " 947: 7.720648095774789,\n",
       " 948: 10.595019512324512,\n",
       " 949: 5.675038586496387,\n",
       " 950: 8.497878393545275,\n",
       " 951: 9.075193758580099,\n",
       " 952: 7.1843433867078135,\n",
       " 953: 9.44988720802151,\n",
       " 954: 9.13973227971767,\n",
       " 955: 8.62890665595168,\n",
       " 956: 7.174953646357975,\n",
       " 957: 10.749170192151771,\n",
       " 958: 10.143034388581455,\n",
       " 959: 9.245092795375497,\n",
       " 960: 8.04111999104956,\n",
       " 961: 9.496407223656403,\n",
       " 962: 9.322053836511625,\n",
       " 963: 8.33623704198886,\n",
       " 964: 10.343705084043606,\n",
       " 965: 9.405435445450676,\n",
       " 966: 8.985581599890413,\n",
       " 967: 4.754377854951114,\n",
       " 968: 8.171481808912805,\n",
       " 969: 8.3512749193534,\n",
       " 970: 6.472504073135715,\n",
       " 971: 8.957410722923715,\n",
       " 972: 9.545197387825835,\n",
       " 973: 8.480486650833406,\n",
       " 974: 6.1456680632643765,\n",
       " 975: 10.23834456838578,\n",
       " 976: 9.832879460277615,\n",
       " 977: 6.606035465760238,\n",
       " 978: 8.184220834690233,\n",
       " 979: 9.322053836511625,\n",
       " 980: 7.027500915214843,\n",
       " 981: 6.778878278599649,\n",
       " 982: 10.23834456838578,\n",
       " 983: 9.173633831393351,\n",
       " 984: 4.176887649457763,\n",
       " 985: 8.086582365126318,\n",
       " 986: 7.945809811245236,\n",
       " 987: 5.489074038423932,\n",
       " 988: 8.366542391484188,\n",
       " 989: 10.056023011591826,\n",
       " 990: 6.197049227253495,\n",
       " 991: 6.61935124173601,\n",
       " 992: 10.749170192151771,\n",
       " 993: 7.681117257018154,\n",
       " 994: 6.8919554232186195,\n",
       " 995: 6.857349894041144,\n",
       " 996: 7.9559621827092535,\n",
       " 997: 6.529662486975664,\n",
       " 998: 6.135701203348984,\n",
       " 999: 9.496407223656403,\n",
       " ...}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_names\n",
    "target = 'label'\n",
    "X = pd.DataFrame(all)\n",
    "y = df['label'].astype(int)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=20000, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = SelectFromModel(LogisticRegression(class_weight='balanced',penalty=\"l1\",C=0.01))\n",
    "X_ = select.fit_transform(X_trainval,y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced',penalty=\"l1\",C=0.01).fit(X_, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import randint, uniform\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# lr = LogisticRegression()\n",
    "# params = {'penalty': ['l1', 'l2'], 'C':np.logspace(-5,0,100)}\n",
    "\n",
    "# search = RandomizedSearchCV(\n",
    "#     pipeline, \n",
    "#     param_distributions=param_distributions, \n",
    "#     n_iter=5, \n",
    "#     cv=2, \n",
    "#     scoring='neg_mean_squared_error', \n",
    "#     verbose=10, \n",
    "#     return_train_score=True, \n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# search.fit(X_train, y_train_log, groups=groups);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr = LogisticRegression()\n",
    "params = {'penalty': ['l1', 'l2'], 'C':np.logspace(-5,0,100)}\n",
    "#Grid searching to find optimal parameters for Logistic Regression\n",
    "gs = GridSearchCV(lr, param_grid=params, cv=10, verbose=1)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_trainval, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = SelectFromModel(LogisticRegression(class_weight='balanced',penalty=\"l1\",C=0.01))\n",
    "X_ = select.fit_transform(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced',penalty=\"l1\",C=0.01).fit(X_, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(text):\n",
    "    \n",
    "    nltk.download('stopwords')\n",
    "\n",
    "    stopwords=stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "    other_exclusions = [\"#ff\", \"ff\", \"rt\"]\n",
    "    stopwords.extend(other_exclusions)\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    def clean(text):\n",
    "        spaces = '\\s+'\n",
    "        urls = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "            '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "        mentions = '@[\\w\\-]+'\n",
    "        parsed_text = re.sub(spaces, ' ', text)\n",
    "        parsed_text = re.sub(urls, '', parsed_text)\n",
    "        parsed_text = re.sub(mentions, '', parsed_text)\n",
    "        return parsed_text\n",
    "    \n",
    "    def tokenize(text):\n",
    "        text = \" \".join(re.split(\"[^a-zA-Z]*\", text.lower())).strip()\n",
    "        tokens = [stemmer.stem(t) for t in text.split()]\n",
    "        return tokens\n",
    "\n",
    "        vectorizer = TfidfVectorizer(\n",
    "        tokenizer=tokenize,\n",
    "        preprocessor=clean,\n",
    "        ngram_range=(1, 3),\n",
    "        stop_words=stopwords,\n",
    "        use_idf=True,\n",
    "        smooth_idf=False,\n",
    "        norm=None,\n",
    "        decode_error='replace',\n",
    "        max_features=10000,\n",
    "        min_df=5,\n",
    "        max_df=0.501\n",
    "        )\n",
    "    \n",
    "    tfidf = vectorizer.fit_transform(text).toarray()\n",
    "    vocab = {v:i for i, v in enumerate(vectorizer.get_feature_names())}\n",
    "    idf_vals = vectorizer.idf_\n",
    "    idf_dict = {i:idf_vals[i] for i in vocab.values()}\n",
    "    \n",
    "    sentiment_analyzer = VS()\n",
    "\n",
    "    def count_twitter_objs(text):\n",
    "    \n",
    "        space_pattern = '\\s+'\n",
    "        giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "            '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "        mention_regex = '@[\\w\\-]+'\n",
    "        hashtag_regex = '#[\\w\\-]+'\n",
    "        parsed_text = re.sub(space_pattern, ' ', text)\n",
    "        parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "        parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "        parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "        return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "\n",
    "    def other_features(text):\n",
    "        sentiment = sentiment_analyzer.polarity_scores(text)\n",
    "\n",
    "        words = clean(text) #Get text only\n",
    "\n",
    "        syllables = textstat.syllable_count(words) #count syllables in words\n",
    "        num_chars = sum(len(w) for w in words) #num chars in words\n",
    "        num_chars_total = len(text)\n",
    "        num_terms = len(text.split())\n",
    "        num_words = len(words.split())\n",
    "        avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "        num_unique_terms = len(set(words.split()))\n",
    "\n",
    "        FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
    "\n",
    "        FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
    "\n",
    "        twitter_objs = count_twitter_objs(text) #Count #, @, and http://\n",
    "        retweet = 0\n",
    "        if \"rt\" in words:\n",
    "            retweet = 1\n",
    "        features = [FKRA, FRE,syllables, avg_syl, num_chars, num_chars_total, num_terms, num_words,\n",
    "                    num_unique_terms, sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound'],\n",
    "                    twitter_objs[2], twitter_objs[1],\n",
    "                    twitter_objs[0], retweet]\n",
    "\n",
    "        return features\n",
    "\n",
    "    def get_feature_array(text):\n",
    "        feats=[]\n",
    "        for t in text:\n",
    "            feats.append(other_features(t))\n",
    "        return np.array(feats)\n",
    "    \n",
    "    feats = get_feature_array(text)\n",
    "    \n",
    "    all = np.concatenate([tfidf,feats],axis=1)\n",
    "    \n",
    "    other_features_names = [\"FKRA\", \"FRE\",\"num_syllables\", \"avg_syl_per_word\", \"num_chars\", \"num_chars_total\", \\\n",
    "                        \"num_terms\", \"num_words\", \"num_unique_words\", \"vader neg\",\"vader pos\",\"vader neu\", \"vader compound\", \\\n",
    "                        \"num_hashtags\", \"num_mentions\", \"num_urls\", \"is_retweet\"]\n",
    "\n",
    "    variables = ['']*len(vocab)\n",
    "    for k,v in vocab.items():\n",
    "        variables[v] = k\n",
    "\n",
    "    features = variables+other_features_names\n",
    "    X = pd.DataFrame(all)\n",
    "    \n",
    "    \n",
    "    return X\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df['text']\n",
    "trial3 = wrangle(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = SelectFromModel(LogisticRegression(class_weight='balanced',penalty=\"l1\",C=0.01))\n",
    "X_ = select.fit_transform(trial2,df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced',penalty=\"l1\",C=0.01).fit(trial2, df['label'])\n",
    "y_pred = model.predict(trial2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(df['label'], y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle2(text):\n",
    "    \n",
    "    nltk.download('stopwords')\n",
    "\n",
    "    stopwords=stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "    other_exclusions = [\"#ff\", \"ff\", \"rt\"]\n",
    "    stopwords.extend(other_exclusions)\n",
    "    \n",
    "#     if type(text)==pd.DataFrame:\n",
    "#         text = text['text']\n",
    "#     if text(text)==list:\n",
    "#         text = text\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    def clean(text):\n",
    "        spaces = '\\s+'\n",
    "        urls = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "            '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "        mentions = '@[\\w\\-]+'\n",
    "        parsed_text = re.sub(spaces, ' ', text)\n",
    "        parsed_text = re.sub(urls, '', parsed_text)\n",
    "        parsed_text = re.sub(mentions, '', parsed_text)\n",
    "        return parsed_text\n",
    "    \n",
    "    def tokenize(text):\n",
    "        text = \" \".join(re.split(\"[^a-zA-Z]*\", text.lower())).strip()\n",
    "        tokens = [stemmer.stem(t) for t in text.split()]\n",
    "        return tokens\n",
    "\n",
    "        vectorizer = TfidfVectorizer(\n",
    "        tokenizer=tokenize,\n",
    "        preprocessor=clean,\n",
    "        ngram_range=(1, 3),\n",
    "        stop_words=stopwords,\n",
    "        use_idf=True,\n",
    "        smooth_idf=False,\n",
    "        norm=None,\n",
    "        decode_error='replace',\n",
    "        max_features=10000,\n",
    "        min_df=5,\n",
    "        max_df=0.501\n",
    "        )\n",
    "    \n",
    "    tfidf = vectorizer.transform(text).toarray()\n",
    "    vocab = {v:i for i, v in enumerate(vectorizer.get_feature_names())}\n",
    "    idf_vals = vectorizer.idf_\n",
    "    idf_dict = {i:idf_vals[i] for i in vocab.values()}\n",
    "    \n",
    "    sentiment_analyzer = VS()\n",
    "\n",
    "    def count_twitter_objs(text):\n",
    "    \n",
    "        space_pattern = '\\s+'\n",
    "        giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "            '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "        mention_regex = '@[\\w\\-]+'\n",
    "        hashtag_regex = '#[\\w\\-]+'\n",
    "        parsed_text = re.sub(space_pattern, ' ', text)\n",
    "        parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "        parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "        parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "        return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "\n",
    "    def other_features(text):\n",
    "        sentiment = sentiment_analyzer.polarity_scores(text)\n",
    "\n",
    "        words = clean(text) #Get text only\n",
    "\n",
    "        syllables = textstat.syllable_count(words) #count syllables in words\n",
    "        num_chars = sum(len(w) for w in words) #num chars in words\n",
    "        num_chars_total = len(text)\n",
    "        num_terms = len(text.split())\n",
    "        num_words = len(words.split())\n",
    "        avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "        num_unique_terms = len(set(words.split()))\n",
    "\n",
    "        FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
    "\n",
    "        FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
    "\n",
    "        twitter_objs = count_twitter_objs(text) #Count #, @, and http://\n",
    "        retweet = 0\n",
    "        if \"rt\" in words:\n",
    "            retweet = 1\n",
    "        features = [FKRA, FRE,syllables, avg_syl, num_chars, num_chars_total, num_terms, num_words,\n",
    "                    num_unique_terms, sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound'],\n",
    "                    twitter_objs[2], twitter_objs[1],\n",
    "                    twitter_objs[0], retweet]\n",
    "\n",
    "        return features\n",
    "\n",
    "    def get_feature_array(text):\n",
    "        feats=[]\n",
    "        for t in text:\n",
    "            feats.append(other_features(t))\n",
    "        return np.array(feats)\n",
    "    \n",
    "    feats = get_feature_array(text)\n",
    "    \n",
    "    all = np.concatenate([tfidf,feats],axis=1)\n",
    "    \n",
    "    other_features_names = [\"FKRA\", \"FRE\",\"num_syllables\", \"avg_syl_per_word\", \"num_chars\", \"num_chars_total\", \\\n",
    "                        \"num_terms\", \"num_words\", \"num_unique_words\", \"vader neg\",\"vader pos\",\"vader neu\", \"vader compound\", \\\n",
    "                        \"num_hashtags\", \"num_mentions\", \"num_urls\", \"is_retweet\"]\n",
    "\n",
    "    variables = ['']*len(vocab)\n",
    "    for k,v in vocab.items():\n",
    "        variables[v] = k\n",
    "\n",
    "    features = variables+other_features_names\n",
    "    X = pd.DataFrame(all)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_test = [\n",
    "    \"The presidency doesnt change who you areit reveals who you are. And weve seen all we need to of Donald Trump.\",\n",
    "    \"Crooked Hillary is spending tremendous amounts of Wall Street money on false ads against me. She is a very dishonest person!\"\n",
    "]\n",
    "\n",
    "Xtest = wrangle2(source_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select = SelectFromModel(LogisticRegression(class_weight='balanced',penalty=\"l1\",C=0.01)\n",
    "# X_ = select.transform(X_trainval,y_trainval)\n",
    "\n",
    "y_predtest = model.predict(Xtest)\n",
    "pd.DataFrame(model.predict_proba(Xtest), columns=[\"Hateful\", \"Offensive\", \"Normal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_two = [\"So Drasko just said he was impressed the girls cooked half a chicken.. They cooked a whole one  #MKR\"]\n",
    "Xtest2 = wrangle2(test_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predtest = model.predict(Xtest2)\n",
    "pd.DataFrame(model.predict_proba(Xtest2), columns=[\"Hateful\", \"Offensive\", \"Normal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = LogisticRegression(class_weight='balanced',penalty=\"l1\",C=0.01)\n",
    "# select = SelectFromModel(estimator)\n",
    "# X_ = select.transform(X_trainval,y_trainval)\n",
    "# estimator.fit(X_,y_trainval)\n",
    "\n",
    "# pd.DataFrame(estimator.predict_proba(Xtest), columns=[\"Hateful\", \"Offensive\", \"Normal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nchib\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\nchib\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l1', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "target = 'label'\n",
    "X = pd.DataFrame(all)\n",
    "y = df['label'].astype(int)\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced',penalty=\"l1\",C=0.01)\n",
    "\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102840, 5467)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33      4470\n",
      "           1       0.88      0.84      0.86     32134\n",
      "           2       0.90      0.93      0.92     46236\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     82840\n",
      "   macro avg       0.70      0.70      0.70     82840\n",
      "weighted avg       0.86      0.86      0.86     82840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_trainval, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "# dump(pipeline, 'pipeline.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['report.joblib']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(report, 'report.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sklearn\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1463,  1462,  1545],\n",
       "       [ 1962, 26903,  3269],\n",
       "       [ 1038,  2082, 43116]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(y_trainval, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    labels = unique_labels(y_true)\n",
    "    columns = [f'Predicted {label}' for label in labels]\n",
    "    index = [f'Actual {label}' for label in labels]\n",
    "    table = pd.DataFrame(confusion_matrix(y_true, y_pred), \n",
    "                         columns=columns, index=index)\n",
    "    return sns.heatmap(table, annot=True, fmt='d', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_trainval, y_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-2580928f830f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                  cv='prefit', n_iter=2, random_state=42)\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mpermuter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_trainval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_trainval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0meli5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpermuter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\eli5\\sklearn\\permutation_importance.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    200\u001b[0m             \u001b[0msi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cv_scores_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             \u001b[0msi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_non_cv_scores_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m         \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\eli5\\sklearn\\permutation_importance.py\u001b[0m in \u001b[0;36m_non_cv_scores_importances\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_non_cv_scores_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mscore_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mbase_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimportances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_score_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbase_score\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimportances\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\eli5\\sklearn\\permutation_importance.py\u001b[0m in \u001b[0;36m_get_score_importances\u001b[1;34m(self, score_func, X, y)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_score_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         return get_score_importances(score_func, X, y, n_iter=self.n_iter,\n\u001b[1;32m--> 231\u001b[1;33m                                      random_state=self.rng_)\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\eli5\\permutation_importance.py\u001b[0m in \u001b[0;36mget_score_importances\u001b[1;34m(score_func, X, y, n_iter, columns_to_shuffle, random_state)\u001b[0m\n\u001b[0;32m     89\u001b[0m         scores_shuffled = _get_scores_shufled(\n\u001b[0;32m     90\u001b[0m             \u001b[0mscore_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns_to_shuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns_to_shuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         )\n\u001b[0;32m     93\u001b[0m         \u001b[0mscores_decreases\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mscores_shuffled\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbase_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\eli5\\permutation_importance.py\u001b[0m in \u001b[0;36m_get_scores_shufled\u001b[1;34m(score_func, X, y, columns_to_shuffle, random_state)\u001b[0m\n\u001b[0;32m     98\u001b[0m                         random_state=None):\n\u001b[0;32m     99\u001b[0m     \u001b[0mXs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter_shuffled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns_to_shuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_shuffled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX_shuffled\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\eli5\\permutation_importance.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     98\u001b[0m                         random_state=None):\n\u001b[0;32m     99\u001b[0m     \u001b[0mXs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter_shuffled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns_to_shuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_shuffled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX_shuffled\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\eli5\\sklearn\\permutation_importance.py\u001b[0m in \u001b[0;36mpd_scorer\u001b[1;34m(model, X, y)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mpd_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mbase_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd_scorer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \"\"\"\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
      "\u001b[1;32m~\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \"\"\"\n\u001b[1;32m--> 281\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    255\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# false positives from overflow in sum method.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mis_float\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;34m'fc'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mis_float\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_float\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.virtualenvs\\dash-app-template-JUXX2GS7\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     36\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0;32m     37\u001b[0m          initial=_NoValue, where=True):\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "permuter = PermutationImportance(model, scoring='neg_mean_squared_error', \n",
    "                                 cv='prefit', n_iter=2, random_state=42)\n",
    "\n",
    "permuter.fit(X_trainval, y_trainval)\n",
    "feature_names = features\n",
    "eli5.show_weights(permuter, top=None, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "coefficients = pd.Series(model.coef_[0], features)\n",
    "coefficients.sort_values(ascending=False).nlargest(10).plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items() if word not in stopwords]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_h = df.text[df['label'] == 0].tolist()\n",
    "corpus_o = df.text[df['label'] == 1].tolist()\n",
    "corpus_n = df.text[df['label'] == 2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('co', 2023),\n",
       " ('https', 1920),\n",
       " ('hate', 679),\n",
       " ('like', 591),\n",
       " ('nigga', 571),\n",
       " ('fucking', 552),\n",
       " ('128514', 483),\n",
       " ('niggas', 439),\n",
       " ('bitch', 362),\n",
       " ('ass', 346),\n",
       " ('people', 340),\n",
       " ('get', 328),\n",
       " ('amp', 310),\n",
       " ('trump', 260),\n",
       " ('idiot', 242),\n",
       " ('fuck', 233),\n",
       " ('faggot', 197),\n",
       " ('white', 193),\n",
       " ('know', 192),\n",
       " ('one', 181),\n",
       " ('stupid', 176),\n",
       " ('want', 167),\n",
       " ('bad', 164),\n",
       " ('ugly', 153),\n",
       " ('say', 153),\n",
       " ('think', 152),\n",
       " ('hell', 151),\n",
       " ('got', 149),\n",
       " ('bitches', 148),\n",
       " ('go', 147)]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_words(corpus_h, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('co', 11293),\n",
       " ('fucking', 10539),\n",
       " ('https', 9599),\n",
       " ('bitch', 9424),\n",
       " ('128514', 5031),\n",
       " ('like', 4128),\n",
       " ('bitches', 3495),\n",
       " ('ass', 3063),\n",
       " ('fucked', 3036),\n",
       " ('fuck', 2727),\n",
       " ('hoes', 2415),\n",
       " ('pussy', 2405),\n",
       " ('get', 2350),\n",
       " ('shit', 2089),\n",
       " ('hoe', 1982),\n",
       " ('http', 1831),\n",
       " ('got', 1824),\n",
       " ('8220', 1479),\n",
       " ('8221', 1432),\n",
       " ('bad', 1387),\n",
       " ('know', 1377),\n",
       " ('amp', 1372),\n",
       " ('nigga', 1311),\n",
       " ('hate', 1283),\n",
       " ('one', 1151),\n",
       " ('128557', 1150),\n",
       " ('want', 1063),\n",
       " ('go', 1063),\n",
       " ('people', 1060),\n",
       " ('lol', 981)]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_words(corpus_o, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('co', 40690),\n",
       " ('https', 39674),\n",
       " ('amp', 3807),\n",
       " ('like', 3343),\n",
       " ('one', 2830),\n",
       " ('get', 2488),\n",
       " ('people', 2252),\n",
       " ('new', 2052),\n",
       " ('love', 1993),\n",
       " ('time', 1967),\n",
       " ('know', 1861),\n",
       " ('today', 1816),\n",
       " ('day', 1774),\n",
       " ('see', 1573),\n",
       " ('good', 1559),\n",
       " ('128514', 1527),\n",
       " ('would', 1507),\n",
       " ('us', 1485),\n",
       " ('via', 1483),\n",
       " ('want', 1385),\n",
       " ('go', 1331),\n",
       " ('great', 1280),\n",
       " ('make', 1275),\n",
       " ('think', 1243),\n",
       " ('back', 1240),\n",
       " ('trump', 1184),\n",
       " ('really', 1180),\n",
       " ('need', 1142),\n",
       " ('much', 1138),\n",
       " ('got', 1121)]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_words(corpus_n, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74615     True\n",
       "25872     True\n",
       "7837      True\n",
       "26749     True\n",
       "37009    False\n",
       "         ...  \n",
       "32551    False\n",
       "6378      True\n",
       "45317     True\n",
       "14401     True\n",
       "63758     True\n",
       "Name: label, Length: 82840, dtype: bool"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred == y_trainval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33      4470\n",
      "           1       0.88      0.84      0.86     32134\n",
      "           2       0.90      0.93      0.92     46236\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     82840\n",
      "   macro avg       0.70      0.70      0.70     82840\n",
      "weighted avg       0.86      0.86      0.86     82840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_trainval, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74615     True\n",
       "25872    False\n",
       "7837     False\n",
       "26749     True\n",
       "37009     True\n",
       "         ...  \n",
       "32551    False\n",
       "6378     False\n",
       "45317    False\n",
       "14401    False\n",
       "63758    False\n",
       "Name: label, Length: 82840, dtype: bool"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trainval_binary = y_trainval != 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_trainval, y_trainval_binary)\n",
    "y_pred_binary = model.predict(X_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.93      0.92     46236\n",
      "        True       0.91      0.87      0.89     36604\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     82840\n",
      "   macro avg       0.90      0.90      0.90     82840\n",
      "weighted avg       0.90      0.90      0.90     82840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_binary = classification_report(y_trainval_binary, y_pred_binary)\n",
    "print(report_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_bi = model.predict_proba(X_trainval)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_trainval_binary==1, y_pred_proba_bi)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
